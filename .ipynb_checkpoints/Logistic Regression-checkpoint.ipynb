{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dcbe704-e5d4-448a-b014-fbfbbf2fbc7b",
   "metadata": {},
   "source": [
    "[TensorFlow](https://www.tensorflow.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a7d3fd-03f5-4fff-8193-903ffdbe90fa",
   "metadata": {},
   "source": [
    "# Logistic Regression with Eager API\n",
    "\n",
    "A logistic regression implemented using TensorFlow's Eager API.\n",
    "\n",
    "- Author: Aymeric Damien\n",
    "- Project: https://github.com/aymericdamien/TensorFlow-Examples/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d43fbe5-7999-495e-a988-c1ea9a45f5cb",
   "metadata": {},
   "source": [
    "## MNIST Dataset Overview\n",
    "\n",
    "This example is using MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 1. For simplicity, each image has been flattened and converted to a 1-D numpy array of 784 features (28*28).\n",
    "\n",
    "![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "More info: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dd7ffc0f-3804-432d-9903-0977fd3a5126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version 2.11.0\n"
     ]
    }
   ],
   "source": [
    "%reset -sf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "print(f'TensorFlow version {tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a490700c-9371-4d6b-94dc-9a9a2de4ff54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"405pt\" height=\"114.431168pt\" viewBox=\"0 0 405 114.431168\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-03-18T21:00:35.254139</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 114.431168 \n",
       "L 405 114.431168 \n",
       "L 405 -0 \n",
       "L 0 -0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g clip-path=\"url(#p573449b30b)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAAHYAAAB2CAYAAAAdp2cRAAAEwElEQVR4nO2db2hVZRzHz/FedV5bzjm1RTivW27+axccteVYQWW+EEEqli8KJhYlOrKJLySwpMhhBRK1QAgNBtqMQEh7Z0PQdGNRbP0ZbU6a2pVtOG0bm7v3+LK+91m7budc77lfv59338Nzz3PYZz+e8+c557GftV90LEHHjHQfgEgNEkuKxJIisaRILCkSS4rEkiKxpEgsKRJLisSSIrGkBL3YSWfD45g3NUx5H5/dKIR8qHk9ZDtmQy55/5Kxj1j0+pT7ZUUVS4rEkiKxpNhePGgfe74M864ByHuLTkFeP2fIbZdWNDZibKs6WQe55J3fIcduDLruN1NQxZIisaRILCmejLHJCOY/BHngy7lGmzfDzZC3ZEdd97vjSiXktoYI5LwT7ZDjt2657tMvqGJJkVhSJJaUezLG3g3BpUsgD67Nh1y9/3vIb+R0u+6z7lo55POflxltco9cxA3xmOt+7wWqWFIklhSJJUViSfHNyVMyguECyF01Dxtt3q0+BvmFB/pc97s3iidUzYfwhGv+0fOu+0gFqlhSJJYUiSUlY8bYu8EuWw25s3YW5MPrjkKuyhqbch+jzm3IL/+5GfLtp69NeZ+pQBVLisSSIrGkUI2xyYhXRiB3vZQFeXWkx/jNN0XfTbrP+v5VkM9GEiYRpOmhgSqWFIklRWJJua/G2OnwdS/eCw7ZeG087OC18Madb2H7by+k5LiSoYolRWJJkVhSPHnxOVMJLF4E+Wp1kdEmy26ZdB+v9WyEnK4xNRFVLCkSS4rEkiKxpNxXJ0/Ougjk0IFeyC3LPp3gV/i/X3JmG+Ti9xLfku+f5tF5iyqWFIklRWJJoR5jB7ZWQG7c9xHkcBAftE/Eqq92QC45jJPVxrt7pndwKUYVS4rEkiKxpFCNsTNKV0A+tu8g5I4xvOm/uRUnezs/zTP2Gf4AH7SPO5kxL0EVS4rEkiKxpGTsGBvIMcfD3Aa8xlwSnAP5lT2vQn7k+I/eH5hPUMWSIrGkSCwpGTvG/la/3NjWWfAF5JrLz0DObpp8YhoTqlhSJJYUiSVFYknx7clTIG8B5Fg/Lvky88HkX3zpaFwJeVH8nPsDyxBUsaRILCkSS4pvxtiBGpx4dnMDLpMW+KUYckfVRJO7kU2v45IvLY15kBOXRHMqSo199NRiDm/5OWm/fkAVS4rEkiKxpKTlqzGJS6JZlmVVn2mF7MUSaIkkLsfS/Q+OuUcKTxi/GYzjn2d7QaXRxo+oYkmRWFIklpS0XMeOFpsrcKzN+ithyyyjjVs+zk82ec18SStk49dLo7VPQg4OTX6Kkn1l3Ng2uw+XIXda2402blHFkiKxpEgsKRJLim8+axtY8ShkZ/ZMyFefyoE8Uo4PCSzLsnLn4bazpce9Obj/cHo4G3J91wbIP6xpgtw7jidKlmVZB6LPQf71w8cge/HZPlUsKRJLisSS4psx1gvsIN5vCSzM+5+WE/PH7qXGtlgoDrmg8Drk0HYb8t+f4I2VtjJznO+L4bnAE011kIvedv8WoCqWFIklRWJJoRpjxb+oYkmRWFIklhSJJUViSZFYUiSWFIklRWJJkVhSJJYUiSVFYkmRWFIklhSJJUViSZFYUiSWFIkl5Q4L0e25Y7CGHQAAAABJRU5ErkJggg==\" id=\"image59c049a357\" transform=\"scale(1 -1) translate(0 -84.96)\" x=\"7.2\" y=\"-22.271168\" width=\"84.96\" height=\"84.96\"/>\n",
       "   </g>\n",
       "   <g id=\"text_1\">\n",
       "    <!-- 5 -->\n",
       "    <g transform=\"translate(45.839022 16.318125) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_2\">\n",
       "   <g clip-path=\"url(#p8d02db1a24)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAAHYAAAB2CAYAAAAdp2cRAAAFdklEQVR4nO2dfUyVVRzHn8vlRXBlCnPEmhDEBaotUWiyVjgpwumyldPYiiRbbpgja7L+kbnWmK1CSaFmlkNnulXWWissldGLOlCpLEQshmkze3Mk48UL9/av3+fcrl65b3z9fv77Ppx7OOzDb+fec87zXMf9jsVeS9ARE+kBiNAgsaRILCkSS4rEkiKxpEgsKRJLisSSIrGkSCwpEkuKxJIisaRILCkSS0psRH5pZoZxrXtVKuSuJZsgx9j+Bz2Wx+gj97MqyDlNg5C9nT8FMswJjSqWFIklRWJJcYTjMJvTlQXZteu00eaV1EN++7iaOdZO5wi+prztGRxH5dEr9jFRUcWSIrGkSCwpYfkce37udMgfpe4OuI+vhuMhnxpJNdpUTumDnJ+A83B36VuQV3fcC7nl4Eyjz+zqwwGMMnpQxZIisaRILCkSS0pENgF8MewdhZy/71nIWdvwjVDc7xeNPt4ufgjytKVnIa+asR9yQ9q3kD+Z32X0WZdZBvnGximQ41s6jNdEA6pYUiSWFIklJTxzrAOjfUHfsiyrbSgZcvYy/wv0Yz6upZz8GS9swdhouSDXvFQE+cOKeqPPw7N2QZ614gnIaS1+hxkxVLGkSCwpEktKeOZY21a+r03y6m/KIbus0G+Cp9fi5v5z+6uMNn89PwT5yN3NkEtalkKeXNYbpNGND1UsKRJLisSSEjVrxa/d8z7kLVZm2McQ09ZpXEvtSIKctx7XsE88uhny3lO4lrx+bYXR5w27Q795r4olRWJJkVhSomaOTXYOQLbfuDXa2xe+wVyGZxBv7Mp58Tjk3NiVkHsWvQl5+0rb+rVlWYN7p0Ieu3BhPEP0iSqWFIklRWJJkVhSwvLmKRbX0a1+zyWjTdEkzL0VaZBnrOsL8qiuDfubKVdVOzZYhHFn5udGH3kNKyBnV+jNk7hKJJYUiSUlLHPsTTtwQ/vl6rlGm9dvxoXx2aV4ePvPdcEeVWiIczghu308L6AsD/+2X0IwDlUsKRJLisSSEpFNgB/WzjSuebYehPxO+peQH3gYF9sTP7Z9fowS3F48yu7r4N6Y12FcCzaqWFIklhSJJSUic2xim/kU0oXdj0D+NHcP5K0NGyAvm/SC0cfUr3+F7J2cCHmsJxSfGKMTVSwpEkuKxJISkTnWvqdpWZblrLkV8pxavMG4vWAn5Pq6RqOPAwO3Q96zaR7k5CiZY9vPpUOebnUH/XeoYkmRWFIklhSJJSVq7gTwHsVFi5T6fMg9zXgALj/BHHp+wo+Q2x7Lhuz8AE/g/7MgB/Lfd5qL867GM5BHz5w12vjj/NiIcS15Y5KPlsFFFUuKxJIisaSE5etZgsHovNmQ33h3s9HGFRdvXLucytMlkI/sy4N8fLnZZ+sQnmR/tfJxyP1Z+PP2OrzbrvDYEqPPaQt7/I4zGKhiSZFYUiSWlKj5HHslYg/gk9rKv3vKaNNRuN1vH/YDcjHL8Ynjvg6eFSfihsWaAty8v2PxCcjGYbYIvYNRxZIisaRILCkTZo61c0vFb8a10vvwUPnqDe9Bnp8U+A3GtX8UQo4bwElzW8YXtldgrfzblWzZSQl4FIGjiiVFYkmRWFIklpQJswlwLbhLCyDXNO2AXGJbfPC1QNHrdkPu9yRAtn9H7YNP4+PnE1vxEX2WZVme4eH/GXHwUMWSIrGkSCwp1HOsHU8xHpDb2NwE+ba4wNdrTrpx0X9NxpzABxYCVLGkSCwpEkvKdTXH2rEfkDtXZR7u/r4Iv/LsrkNPQk5rxAN0ztZjQRrd+FDFkiKxpEgsKdf1HMuMKpYUiSVFYkmRWFIklhSJJUViSZFYUiSWFIklRWJJkVhSJJYUiSVFYkmRWFL+Ax3nJko/4CmfAAAAAElFTkSuQmCC\" id=\"image4a7c5b8578\" transform=\"scale(1 -1) translate(0 -84.96)\" x=\"109.095652\" y=\"-22.271168\" width=\"84.96\" height=\"84.96\"/>\n",
       "   </g>\n",
       "   <g id=\"text_2\">\n",
       "    <!-- 0 -->\n",
       "    <g transform=\"translate(147.734674 16.318125) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_3\">\n",
       "   <g clip-path=\"url(#p5461368005)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAAHYAAAB2CAYAAAAdp2cRAAAEAklEQVR4nO2dS0hUYRiGz5kxb1FoXkhTygQx6GLQEN0oYVpLZC5cBKkU1SYpaCUtitq6cGPLqFUGloISGV6KKCuNkC5YeanwUlKCGuo4LeudI+Ycz3Gct/fZvTOe/3zw+PH9Z45nNP1mcdAQdHgiXYBwB4klRWJJkVhSJJYUiSVFYkmRWFIklhSJJUViSZFYUmIiXcBKZ6hyL+SXF2og57eVQd5c2u12SYtCHUuKxJIisaRoxv6DOP8oZK8ZHb0QHVWKsJFYUiSWFM3YMAkE5yJdwqJQx5IisaRILCmasUsksTMx0iXMizqWFIklRWJJkVhStHkKE8tNgBX6eYU6lhSJJUViSdGMDZPQmwDJ72ciVMnCqGNJkVhSJJYUiSVFYkmRWFIklhRdxy6R/iITcl5ThAoJQR1LisSSIrGkODJjP13bAznb98WJZYHRpizIKT3Wz2hjmzsdP+9kexq+UIDxSuEdyDeMbMdrsIM6lhSJJUViSZFYUmxtnnpv7oT8thC/SeXNDG5s7o0XhH2Oiyk9kD1b8IOAqeC05ZivgQDkmtFDkBte7YCc1BULOeP+sGXNrOoXkDtP4TftF63GjaI2T8JVJJYUiSXF1oyNi8cZ6jFw/p24Wgk59fqTsM/RdqACctCL5xj0x1mOmc4MqSsWZ+4DfzXkVYfx+KHz1jWrPh6BnOadwjVMPMb0bYMc7HxtWXM5UMeSIrGkSCwprtxoTxhb+pNKno6uBd/f1Br+mmeM/ZC9qSmQh4/mWY5ZV/IZswd7Icbw4hq710BOd/6+xKJQx5IisaRILCmuzNiRXfj7klPnxlmWTuDbd8iptfNcb9diPFhfDrnLdwvy6bP1kOtvb7Wed3hk8UXaRB1LisSSIrGk2Jqxs714rWbg37IZ8fk/bJaz8sk+NwH58UPsjfK1eN1bn4T/BcQwDMPQjBV2kVhSJJYUiSXF1uZpYyPebB4pnXSkmGhgtm8Act2YD/K+jKeQp3KSLWvEvnO+rlDUsaRILCkSS4qtGet51A2549cGJ2qJSvomUhZ8f9DvtbyW2+xWNX9Qx5IisaRILCmO3GifCf6/Xz4zWxHy71laMSbkji9bLX+jjiVFYkmRWFIcGY6XGo9BTsz96cSyUUHgQz/k/LYyyCe3d1iOafHhzXc3HtxSx5IisaRILCkSS4ojm6fMdny6bqonyYllo4M5fGreHEiA3LI+33pMMGh9zWHUsaRILCkSS4ojMzbh7jPMTiwapaQ/x/1GVUmD5WcuG8ddr0MdS4rEkiKxpJh+s9j9iyqx7KhjSZFYUiSWFIklRWJJkVhSJJYUiSVFYkmRWFIklhSJJUViSZFYUiSWFIklRWJJkVhSJJYUiSXlN7oyqbw38WkJAAAAAElFTkSuQmCC\" id=\"image2e631e657d\" transform=\"scale(1 -1) translate(0 -84.96)\" x=\"210.991304\" y=\"-22.271168\" width=\"84.96\" height=\"84.96\"/>\n",
       "   </g>\n",
       "   <g id=\"text_3\">\n",
       "    <!-- 4 -->\n",
       "    <g transform=\"translate(249.630326 16.318125) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_4\">\n",
       "   <g clip-path=\"url(#p149219af22)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAAHYAAAB2CAYAAAAdp2cRAAADuUlEQVR4nO3dS0hUYRwF8BkfMaabQmSqGS0CFRRJMEopNEqKFhUySrWzVj3tCQUuWrWI6CEFJkEQmpQJ1i4IIorIigLzQWFhPqgQNUJD1JlpES3Ovdpoc9V7j+e3O8OdywfHPx8znzPj3uIOhF1CJ2a+FyCzQ8WSUrGkVCwpFUtKxZJSsaRULCkVS0rFklKxpFQsqbj5XsBfcavSIHvrByBX+59CvjecYrrH7Qy/9QtzKE0sKRVLSsWSss0e+3ONF3KDr8FwRezcLYaAJpaUiiWlYkmpWFIqlpSKJaViSdnmdaxncAzy89FEyJsSRiFvXdxtukdlTQnkzOPtkEMjI9Es0VE0saRULCkVS0rFknLb9dN2PfezIbcX1EIeDwcj3mNn8R7IwfaP0S/MITSxpFQsKRVLyjZvUBj5A62Qx/twT53OHvu1KBlyivZYcToVS0rFkrLtHmv0biwEOTs+8nPyy99C7qpfAjk4NBT1uuxKE0tKxZJSsaRs+16xUagwF/L+mibTNTsSv//zHsWtuyEnbfsc9brsShNLSsWSUrGkHLPHGn2qyzU91lJ4Y0b3KNm1D3L4TesUVzqPJpaUiiWlYkmpWFKOOQQwSj//y/RYfNHMPvXefQazPxDNiuxFE0tKxZJSsaQcu8cG2z6YHiuoPAy57txFyL5YPJ3P93VB/rYy1XTPiS7zp/qcQBNLSsWSUrGkHHsIMB29Zwsgvz50BXK8G1/3lnZuN91jLID/RBfs77dmcbNME0tKxZJSsaSo99jYrAzIa+/gQXplcgvkyT7olXP3KOTVJ19atLrZpYklpWJJqVhS1HusUZxvBeSm5oeQJ9tjO8YxV5w6AjmxsdmaxVlME0tKxZJSsaRULCnHHrT/j4nePshZz8oht228ZXpOziLMqSfwm2cGGq1Zm9U0saRULCkVS2pB7bFGy2o9kJ/keUzXbPDg183fTHsEOb/iGGTv1RfWLC5KmlhSKpaUiiW1oA4BIhkuXWd67PqFKsjp8W7I1T8yIT8uy4Mc/oKvnV2uufmZGE0sKRVLSsWS0h4bQeel9ZDfl1VNceUfxn9C33zwgOmahAevol9YBJpYUiqWlIolpWJJLehDgOlI6sG//cEQ/s7t0hjDSbxNaGJJqVhSKpaU9tgIvJfx4Lxo+WnIHXuvQTa+QeHCM4M5o4klpWJJqVhSOgQgpYklpWJJqVhSKpaUiiWlYkmpWFIqlpSKJaViSalYUiqWlIolpWJJqVhSKpaUiiWlYkmpWFIqltRvlnSlzXtGJDMAAAAASUVORK5CYII=\" id=\"image79428f2a05\" transform=\"scale(1 -1) translate(0 -84.96)\" x=\"312.886957\" y=\"-22.271168\" width=\"84.96\" height=\"84.96\"/>\n",
       "   </g>\n",
       "   <g id=\"text_4\">\n",
       "    <!-- 1 -->\n",
       "    <g transform=\"translate(351.525978 16.318125) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p573449b30b\">\n",
       "   <rect x=\"7.2\" y=\"22.318125\" width=\"84.913043\" height=\"84.913043\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p8d02db1a24\">\n",
       "   <rect x=\"109.095652\" y=\"22.318125\" width=\"84.913043\" height=\"84.913043\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p5461368005\">\n",
       "   <rect x=\"210.991304\" y=\"22.318125\" width=\"84.913043\" height=\"84.913043\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p149219af22\">\n",
       "   <rect x=\"312.886957\" y=\"22.318125\" width=\"84.913043\" height=\"84.913043\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 700x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize = (7, 3))\n",
    "for img, label, ax in zip(x_train[:4], y_train[:4], axes):\n",
    "    ax.set_title(label)\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c12d5011-b781-4ed7-8a67-8d5fb83e09e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images: (60000, 28, 28)\n",
      "train images: (60000,)\n",
      "train images: (10000, 28, 28)\n",
      "train images: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(f'train images: {x_train.shape}')\n",
    "print(f'train images: {y_train.shape}')\n",
    "print(f'train images: {x_test.shape}')\n",
    "print(f'train images: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bafbea-bce0-4897-8c09-d20d9a65a327",
   "metadata": {},
   "source": [
    "# Preprocesssing: flatten and rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b436ca8-df1f-403a-a9f4-7e80dd9e2153",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784) / 255\n",
    "x_test = x_test.reshape(10000, 784) / 255\n",
    "\n",
    "y_train = tf.one_hot(y_train,10)\n",
    "y_test = tf.one_hot(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c24c8855-2163-4c18-ba45-7e36c7b110e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0af4af8-156d-4da7-be6a-695ea1e1673c",
   "metadata": {},
   "source": [
    "## Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f87f2fdd-7f95-4a53-9829-1328e0df0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "batches = int(x_train.shape[0] / batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52845dc-cf9f-4158-b29a-32b1fb2ada25",
   "metadata": {},
   "source": [
    "$Y = \\sigma(X \\cdot W + B)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce04f95d-b404-431a-a1b7-0ea74d682136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow._api.v2.version' from '/home/sprk/devel/miniconda3/envs/tf310/lib/python3.10/site-packages/tensorflow/_api/v2/version/__init__.py'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf Graph Input\n",
    "# X is our \"flattened / normalized\" images\n",
    "# Y is our \"one hot\" labels\n",
    "#X = tf.placeholder(dtype=tf.float32, shape=[None, 784]) # mnist data image of shape 28*28=784\n",
    "#Y = tf.placeholder(dtype=tf.float32, shape=[None, 10]) # 0-9 digits recognition => 10 classes\n",
    "\n",
    "# Set model weights\n",
    "W = tf.random.normal(shape=[784, 10])\n",
    "B = tf.random.normal(shape=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a168c6c9-fcba-43c6-98d3-83607c9d29f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Construct model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pred \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(tf\u001b[38;5;241m.\u001b[39mmatmul(\u001b[43mX\u001b[49m, W) \u001b[38;5;241m+\u001b[39m b) \u001b[38;5;66;03m# Softmax\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Minimize error using cross entropy\u001b[39;00m\n\u001b[1;32m      5\u001b[0m cost \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(\u001b[38;5;241m-\u001b[39mtf\u001b[38;5;241m.\u001b[39mreduce_sum(Y\u001b[38;5;241m*\u001b[39mtf\u001b[38;5;241m.\u001b[39mlog(pred), reduction_indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Construct model\n",
    "pred = tf.nn.softmax(tf.matmul(X, W) + b) # Softmax\n",
    "\n",
    "# Minimize error using cross entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(pred), reduction_indices=1))\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7036d539-d76e-4633-a4d0-35fea3564755",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf55548-164b-4fb0-b37e-cdf3d1806a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # Fit training using batch data\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs,\n",
    "                                                          y: batch_ys})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost)\n",
    "\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy for 3000 examples\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print \"Accuracy:\", accuracy.eval({x: mnist.test.images[:3000], y: mnist.test.labels[:3000]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
